{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from toolz import concat, concatv, first, peek\n",
    "from itertools import starmap\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbc_analysis.utils.debug_utils import runit\n",
    "from nbc_analysis.utils.config_utils import get_config\n",
    "from nbc_analysis.analysis.gen_profiles import main as gen_profile\n",
    "from nbc_analysis.transforms.merge_video_ends import main as merge_video_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex_common.types import EntityEvent, StringAttributeValue, ListAttributeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> created example config file '/Users/wmcabee/.config/nbc_analysis/config_example.yaml'\n",
      ">> Using default config\n",
      ">> WARNING: Overriding config file values with : {'BATCHES_D': '/Users/wmcabee/Dropbox (Cognitive Scale)/NBC Analysis/data/NBC2/batches'}\n"
     ]
    }
   ],
   "source": [
    "config = get_config(config_f='default',\n",
    "                      overrides={'BATCHES_D': '/Users/wmcabee/Dropbox (Cognitive Scale)/NBC Analysis/data/NBC2/batches'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading batches,batch_cnt=129,indir=/Users/wmcabee/Dropbox (Cognitive Scale)/NBC Analysis/data/NBC2/batches\n",
      ">> Building index on {mpid,event_start_unixtime_ms}\n",
      ">> Sorting index\n",
      ">> end merge ve_events,outfile=/Users/wmcabee/DATA/NBC2/work/merged_ve_events.parquet,records=6265392\n",
      "CPU times: user 1min 19s, sys: 7.16 s, total: 1min 26s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DATA = merge_video_ends(config_f=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "df= DATA[['show','genre']]\n",
    "#df = df[:200]\n",
    "df = df.reset_index()\n",
    "GENRES = df.genre.drop_duplicates(keep='last').tolist()\n",
    "SHOWS = df.show.drop_duplicates(keep='last').sort_values().tolist()\n",
    "\n",
    "reader = filter(None, concatv(GENRES, SHOWS))\n",
    "reader = concat(map(lambda x: x.split(' '),reader ))\n",
    "reader = (x.lower() for x in reader if x.isalpha())\n",
    "KEYWORDS = list(set(reader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DATA[:2000].reset_index()[['mpid', 'event_start_unixtime_ms']].sample(frac=1)\n",
    "MPIDS = df.mpid\n",
    "MPIDS_TS = df.event_start_unixtime_ms.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_scores(choices):\n",
    "    count = np.random.randint(5,10)\n",
    "    reader = zip(np.random.choice(choices,count, replace=False ),\n",
    "              np.round(np.random.rand(count),5) )\n",
    "    reader = filter(lambda x: x[0] not in {'', None}, reader)\n",
    "    return sorted(reader, key=lambda x: -x[1])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_profile(mpid, mpid_ts):\n",
    "    return dict(mpid=mpid,\n",
    "                genres=mock_scores(GENRES),\n",
    "                shows=mock_scores(SHOWS),\n",
    "                event_start_unixtime_ms=mpid_ts,\n",
    "                #keywords=mock_scores(KEYWORDS),\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts2json(inputs, outfile):\n",
    "    reader = map(json.dumps, inputs)\n",
    "    reader = map(lambda x: x+\"\\n\", reader)\n",
    "    reader = list(reader)\n",
    "\n",
    "\n",
    "    with gzip.open(str(outfile), 'wt') as fh:\n",
    "        fh.writelines(reader )\n",
    "    print(f\"wrote file={outfile},len={len(reader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file=ex_from_cs1.json.gz,len=2000\n",
      "example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mpid': -9220657203495870507,\n",
       " 'genres': [('Comedy', 0.88688),\n",
       "  ('Horror and Thriller', 0.88377),\n",
       "  ('Sports', 0.67464),\n",
       "  ('Crime and Mystery', 0.55149),\n",
       "  ('Action and Adventure', 0.28971),\n",
       "  ('Reality and Game Show', 0.08159)],\n",
       " 'shows': [('Jurassic Park III', 0.8296),\n",
       "  ('Beyond Sherwood Forest', 0.67711),\n",
       "  ('Law & Order: Special Victims Unit', 0.61222),\n",
       "  ('Outsourced', 0.53266),\n",
       "  ('Independence Day-saster', 0.45241),\n",
       "  ('Killjoys', 0.24296),\n",
       "  ('Underworld: Rise of the Lycans', 0.16599)],\n",
       " 'event_start_unixtime_ms': 1562216450152}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile = Path('.') / 'ex_from_cs1.json.gz'     \n",
    "INPUTS = list(starmap(mock_profile, zip(MPIDS, MPIDS_TS)))\n",
    "write_dicts2json(inputs=INPUTS, outfile=outfile)\n",
    "print('example:')\n",
    "INPUTS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to profile of 1 input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': 'genres',\n",
       " 'entityId': '-9220657203495870507',\n",
       " 'entityType': 'nbc/Viewer',\n",
       " 'properties': {'value': [{'value': 'Comedy',\n",
       "    'weight': 0.88688,\n",
       "    'context': 'cortex/attribute-value-string'},\n",
       "   {'value': 'Horror and Thriller',\n",
       "    'weight': 0.88377,\n",
       "    'context': 'cortex/attribute-value-string'},\n",
       "   {'value': 'Sports',\n",
       "    'weight': 0.67464,\n",
       "    'context': 'cortex/attribute-value-string'},\n",
       "   {'value': 'Crime and Mystery',\n",
       "    'weight': 0.55149,\n",
       "    'context': 'cortex/attribute-value-string'},\n",
       "   {'value': 'Action and Adventure',\n",
       "    'weight': 0.28971,\n",
       "    'context': 'cortex/attribute-value-string'},\n",
       "   {'value': 'Reality and Game Show',\n",
       "    'weight': 0.08159,\n",
       "    'context': 'cortex/attribute-value-string'}],\n",
       "  'context': 'cortex/attribute-value-list'},\n",
       " 'meta': {},\n",
       " 'eventTime': 1562216450152}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mock_po1( msg, attr, items):\n",
    "    \n",
    "    try: \n",
    "        items = ListAttributeValue(value=list(StringAttributeValue(value=value, weight=weight) for value, weight in items))\n",
    "    \n",
    "        event = EntityEvent(\n",
    "              event=attr,\n",
    "              entityId=str(msg['mpid']),\n",
    "              entityType=\"nbc/Viewer\",\n",
    "              properties=items,\n",
    "              meta= {},\n",
    "              eventTime= msg['event_start_unixtime_ms'],\n",
    "        )\n",
    "        return dict(event)\n",
    "    except Exception as e:\n",
    "        print(items)\n",
    "        raise\n",
    "        \n",
    "reader = ( (msg, attr, items) for msg in INPUTS for attr, items in msg.items() if attr not in {'mpid', 'event_start_unixtime_ms'})\n",
    "reader = starmap(mock_po1, reader)\n",
    "PROFILE_INPUTS = list(reader)\n",
    "PROFILE_INPUTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file=ex_profile_input.json.gz,len=4000\n"
     ]
    }
   ],
   "source": [
    "outfile = Path('.') / 'ex_profile_input.json.gz'     \n",
    "write_dicts2json(inputs=PROFILE_INPUTS, outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringAttributeValue(value='x', weight=3, context='cortex/attribute-value-string')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StringAttributeValue(value='x', weight=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
